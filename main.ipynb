{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "from goodreads_book_scraper import get_listopia\n",
    "from book_importer import BookImporter\n",
    "from language_analysis import Book\n",
    "from similarity import SimilarityChecker\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of books from GoodReads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the URL from the GoodReads website\n",
    "best_books_ever_url = 'https://www.goodreads.com/list/show/1.Best_Books_Ever'\n",
    "large_book_list_url = 'https://www.goodreads.com/list/show/952.1001_Books_You_Must_Read_Before_You_Die'\n",
    "this_week_url = 'https://www.goodreads.com/book/most_read'\n",
    "\n",
    "# Scrape the website and return lists of books, authors and average review\n",
    "goodreads_list, author_list, review_list = get_listopia(large_book_list_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty book_data list to store the books in\n",
    "book_data = []\n",
    "\n",
    "# Iterate through the book list and check if it is on Gutenberg\n",
    "for count, book in enumerate(goodreads_list):\n",
    "    file_path, book_id = BookImporter.gutendex(book, author_list[count])\n",
    "    \n",
    "    # Store the book in the book list\n",
    "    book_data.append({'GutenbergID': book_id, 'Title': book, 'Author': author_list[count], 'Review': review_list[count], 'FilePath': file_path})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the book list into a pandas and check for missing values\n",
    "book_data = pd.DataFrame(book_data)\n",
    "book_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = book_data.duplicated()\n",
    "\n",
    "duplicate_rows = book_data[duplicates]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are any duplicate values (check by title and author), remove them\n",
    "book_data = book_data.drop_duplicates(subset=['Title', 'Author'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataframe\n",
    "print(book_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of unique author names\n",
    "author_list = book_data['Author'].unique()\n",
    "author_list_df = pd.DataFrame({'Name': author_list})\n",
    "\n",
    "print(author_list_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data to SQL database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the SQL database \n",
    "conn = sqlite3.connect('databases/book_repository.db')\n",
    "cursor = conn.cursor()\n",
    "engine = create_engine('sqlite:///databases/book_repository.db')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the tables (Commented out after the first iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Authors table\n",
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS Authors(\n",
    "            AuthorID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            Name VARCHAR\n",
    "        )\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gutenberg table\n",
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Gutenberg(\n",
    "        GutenbergID INTEGER PRIMARY KEY,\n",
    "        FilePath VARCHAR\n",
    "        );\n",
    "    ''')\n",
    "        # If there is not GutenbergID, it will reference this\n",
    "    # conn.execute('''\n",
    "    #     INSERT INTO Gutenberg (GutenbergID, FilePath)\n",
    "    #     VALUES (0, 'Not Available')    \n",
    "    # ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Books table\n",
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Books(\n",
    "        GutenbergID VARCHAR(7),\n",
    "        Title VARCHAR,\n",
    "        AuthorID INTEGER,\n",
    "        Review DOUBLE,\n",
    "        FOREIGN KEY (GutenbergID) REFERENCES Gutenberg(GutenbergID)\n",
    "        FOREIGN KEY (AuthorID) REFERENCES Authors(AuthorID)\n",
    "        );\n",
    "''')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the data in a temporary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the books data into a temporary SQL table\n",
    "book_data.to_sql('temp_books', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the author list into a temporary SQL table\n",
    "author_list_df.to_sql('temp_authors', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the author names into the table, ignore repetitions\n",
    "with engine.begin() as connection:\n",
    "    conn.execute(\"\"\"\n",
    "        INSERT INTO Authors (Name)\n",
    "        SELECT DISTINCT LOWER(t.Name)\n",
    "        FROM temp_authors AS t\n",
    "        LEFT JOIN Authors AS a ON LOWER(t.Name) = LOWER(a.Name)\n",
    "        WHERE a.Name IS NULL\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "        INSERT INTO Gutenberg (GutenbergID, FilePath)\n",
    "        SELECT t.GutenbergID, t.FilePath\n",
    "        FROM temp_books as t\n",
    "        LEFT JOIN Gutenberg AS g ON t.GutenbergID = g.GutenbergID\n",
    "        WHERE t.FilePath IS NOT NULL\n",
    "          AND (g.GutenbergID IS NULL OR g.GutenbergID = 0)\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the rest of the Book data, with the foreign keys\n",
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "        INSERT INTO Books (GutenbergID, Title, AuthorID, Review)\n",
    "        SELECT t.GutenbergID, t.Title, a.AuthorID, t.Review\n",
    "        FROM temp_books AS t\n",
    "        LEFT JOIN Authors AS a ON LOWER(t.Author) = LOWER(a.Name)\n",
    "        LEFT JOIN Books AS b ON t.GutenbergID = b.GutenbergID\n",
    "        WHERE b.GutenbergID IS NULL\n",
    "    ''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the temporary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the temporary tables\n",
    "with engine.begin() as connection:\n",
    "    conn.execute(\"DROP TABLE IF EXISTS temp_books\")\n",
    "    conn.execute('DROP TABLE IF EXISTS temp_authors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if the Data was inserted correctly\n",
    "cursor.execute('''\n",
    "    SELECT Books.Title, Authors.Name, Books.GutenbergID\n",
    "    FROM Books\n",
    "    LEFT OUTER JOIN Authors ON Books.AuthorID = Authors.AuthorID\n",
    "''')\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(f'{row[0]}: {row[1]}, {row[2]}')\n",
    "print(len(rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the Gutenberg table was inserted correctly\n",
    "cursor.execute('SELECT * FROM Gutenberg')\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(f'{row[0]:>7}: {row[1]}')\n",
    "print(len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM Gutenberg WHERE GutenbergID=0')\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SQL server\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NLP and add TextBlob to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the large dataset and add the TextBlob pipeline\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "# Create a books list to store the Book objects\n",
    "books = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the files and analyse the novels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jekyll and Hyde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Jekyll and Hyde from Gutenberg\n",
    "BookImporter.get_book(43, 'Jekyll and Hyde')\n",
    "\n",
    "# Read the txt file and create a Book object\n",
    "with open('data\\Jekyll_and_Hyde.txt', 'r', encoding='UTF-8') as file:\n",
    "    jekyll_hyde = Book('Jekyll and Hyde', file.read())\n",
    "\n",
    "# Denote the chapter markers in a regex expression\n",
    "chapter_markers = r'((\\nSTORY OF THE DOOR)|(\\nSEARCH FOR MR. HYDE)|(\\nDR. JEKYLL WAS QUITE AT EASE)|(\\nTHE CAREW MURDER CASE)|(\\nINCIDENT OF THE LETTER)|(\\nINCIDENT OF DR. LANYON)|(\\nINCIDENT AT THE WINDOW)|(\\nTHE LAST NIGHT)|(\\nDR. LANYON’S NARRATIVE)|(\\nHENRY JEKYLL’S FULL STATEMENT OF THE CASE))'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the book into chapters\n",
    "jekyll_hyde.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct NLP analysis sentence by sentence\n",
    "jekyll_hyde.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do NLP on each chapter\n",
    "jekyll_hyde.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sentiment analysis of the entire text\n",
    "jekyll_hyde.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the analysis of the book\n",
    "jekyll_hyde.get_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the sentiment analysis by chapter\n",
    "jekyll_hyde.chapter_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the book to the book object list\n",
    "books.append(jekyll_hyde)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dracula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\Dracula.txt', 'r', encoding='UTF-8') as file:\n",
    "    dracula = Book('Dracula', file.read())\n",
    "chapter_markers = r'(PREFACE.)|(LETTER I+\\.)|(CHAPTER [IVXLCDM]+\\n)'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.chapter_analysis()\n",
    "books.append(dracula)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frankenstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(84, 'Frankenstein')\n",
    "with open('data\\Frankenstein.txt', 'r', encoding='UTF-8') as file:\n",
    "    frankenstein = Book('Frankenstein', file.read())\n",
    "\n",
    "chapter_markers = r'\\n((Letter .)|(Chapter .+))'\n",
    "frankenstein.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.chapter_analysis()\n",
    "books.append(frankenstein)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Turn of the Screw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(209, 'The Turn of the Screw')\n",
    "with open('data\\The_Turn_of_the_Screw.txt', 'r', encoding='UTF-8') as file:\n",
    "    turn_of_the_screw = Book('The Turn of the Screw', file.read())\n",
    "\n",
    "chapter_markers = r'((\\nI\\n)|(\\nII)|(\\nIII)|(\\nIV)|(\\nV)|(\\nVI)|(\\nVII)|(\\nVIII)|(\\nIX)|(\\nX)|(\\nXI)|(\\nXII)|(\\nXIII)|(\\nXIV)|(\\nXV)|(\\nXVI)|(\\nXVII)|(\\nXVIII)|(\\nXIX)|(\\nXX)|(\\nXXI)|(\\nXXII)|(\\nXXIII)|(\\nXXIV))'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.chapter_analysis()\n",
    "books.append(turn_of_the_screw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Romeo and Juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(1513, 'Romeo and Juliet')\n",
    "with open('data\\Romeo_and_Juliet.txt', 'r', encoding='UTF-8') as file:\n",
    "    romeo_and_juliet = Book('Romeo and Juliet', file.read())\n",
    "\n",
    "chapter_markers = r'(THE PROLOGUE\\n)|(SCENE I. A public place)|(SCENE II. A Street)|(SCENE III. Room in Capulet’s House)|(SCENE IV. A Street)|(SCENE V. A Hall in Capulet’s House)|(ACT II\\n\\n)|(SCENE I. An open place adjoining Capulet’s Garden)|(SCENE II. Capulet’s Garden)|(SCENE III. Friar Lawrence’s Cell)|(SCENE IV. A Street)|(SCENE V. Capulet’s Garden)|(SCENE VI. Friar Lawrence’s Cell)|(SCENE I. A public Place)|(SCENE II. A Room in Capulet’s House)|(SCENE III. Friar Lawrence’s cell)|(SCENE IV. A Room in Capulet’s House)|(SCENE V. An open Gallery to Juliet’s Chamber, overlooking the Garden)|(SCENE I. Friar Lawrence’s Cell)|(SCENE II. Hall in Capulet’s House)|(SCENE III. Juliet’s Chamber)|(SCENE IV. Hall in Capulet’s House)|(SCENE V. Juliet’s Chamber; Juliet on the bed)|(SCENE I. Mantua. A Street)|(SCENE II. Friar Lawrence’s Cell)|(SCENE III. A churchyard; in it a Monument belonging to the Capulets)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.chapter_analysis()\n",
    "books.append(romeo_and_juliet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alice's Adventures in Wonderland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(11, 'Alice’s Adventures in Wonderland')\n",
    "with open('data\\Alice’s_Adventures_in_Wonderland.txt', 'r', encoding='UTF-8') as file:\n",
    "    alice = Book('Alice in Wonderland', file.read())\n",
    "chapter_markers = r'(CHAPTER I.\\nDown the Rabbit-Hole)|(CHAPTER II.\\nThe Pool of Tears)|(CHAPTER III.\\nA Caucus-Race and a Long Tale)|(CHAPTER IV.\\nThe Rabbit Sends in a Little Bill)|(CHAPTER V.\\nAdvice from a Caterpillar)|(CHAPTER VI.\\nPig and Pepper)|(CHAPTER VII.\\nA Mad Tea-Party)|(CHAPTER VIII.\\nThe Queen’s Croquet-Ground)|(CHAPTER IX.\\nThe Mock Turtle’s Story)|(CHAPTER X.\\nThe Lobster Quadrille)|(CHAPTER XI.\\nWho Stole the Tarts\\?)|(CHAPTER XII.\\nAlice’s Evidence)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.chapter_analysis()\n",
    "books.append(alice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The War of the Worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(36, 'War of the Worlds')\n",
    "with open('data\\War_of_the_Worlds.txt', 'r', encoding='UTF-8') as file:\n",
    "    war_of_the_worlds = Book('War of the Worlds', file.read())\n",
    "\n",
    "chapter_markers = r'\\n[IVX]+\\.\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.chapter_analysis()\n",
    "books.append(war_of_the_worlds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wuthering Heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\Wuthering_Heights.txt', 'r', encoding='UTF-8') as file:\n",
    "    wuthering_heights = Book('Wuthering Heights', file.read())\n",
    "\n",
    "chapter_markers = r'CHAPTER [IVX]+'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.chapter_analysis()\n",
    "books.append(wuthering_heights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pride and Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\Pride_and_Prejudice.txt', 'r', encoding='UTF-8') as file:\n",
    "    pride_prejudice = Book('Pride and Prejudice', file.read())\n",
    "\n",
    "chapter_markers = r'(Chapter I\\.\\])|CHAPTER [IVXL]+\\.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.split_into_chapters(chapter_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.do_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.chapter_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.chapter_analysis()\n",
    "books.append(pride_prejudice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\Moby-Dick_or,_the_Whale.txt', 'r', encoding='UTF-8') as file:\n",
    "    moby_dick = Book('Moby Dick', file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r'(\\nCHAPTER .+)|(\\nEPILOGUE.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "moby_dick.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.do_nlp(nlp, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.chapter_analysis()\n",
    "books.append(moby_dick)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ulysses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(4300, 'Ulysses')\n",
    "with open('data\\\\Ulysses.txt', 'r', encoding='UTF-8') as file:\n",
    "    ulysses = Book('Ulysses', file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r''\n",
    "for i in range(1, 18):\n",
    "    chapter_markers += r'(\\n\\[ {} \\])|'.format(i)\n",
    "chapter_markers += r'(\\n\\[ 18 \\])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ulysses.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulysses.do_nlp(nlp, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulysses.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulysses.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ulysses.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulysses.chapter_analysis()\n",
    "books.append(ulysses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Christmas Carol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\A_Christmas_Carol.txt', 'r', encoding='UTF-8') as file:\n",
    "    christmas_carol = Book('A Christmas Carol', file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r'STAVE (.+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.split_into_chapters(chapter_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.do_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.chapter_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.get_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.chapter_analysis()\n",
    "books.append(christmas_carol)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dorian Grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\The_Picture_of_Dorian_Gray.txt', 'r', encoding='UTF-8') as file:\n",
    "    dorian_gray = Book('The Picture of Dorian Gray', file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r'\\n(CHAPTER .+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.split_into_chapters(chapter_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.do_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.chapter_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.get_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.chapter_analysis()\n",
    "books.append(dorian_gray)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## War and Peace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\War_and_Peace.txt', 'r', encoding='UTF-8') as file:\n",
    "    war_and_peace = Book('War and Peace', file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r'\\nCHAPTER [IXVC]+\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.split_into_chapters(chapter_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.do_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.chapter_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.get_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.chapter_analysis()\n",
    "books.append(war_and_peace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct similarity analysis and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a similarity analysis between each book in the books list\n",
    "checker = SimilarityChecker(books)\n",
    "checker.calculate_all_similarities()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results of the similarity analysis\n",
    "checker.display_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
