{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "\n",
    "from goodreads_book_scraper import get_listopia\n",
    "from book_importer import BookImporter\n",
    "from language_analysis import Book\n",
    "from similarity import SimilarityChecker\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a list of books from GoodReads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the URL from the GoodReads website\n",
    "best_books_ever_url = 'https://www.goodreads.com/list/show/1.Best_Books_Ever'\n",
    "large_book_list_url = 'https://www.goodreads.com/list/show/952.1001_Books_You_Must_Read_Before_You_Die'\n",
    "this_week_url = 'https://www.goodreads.com/book/most_read'\n",
    "\n",
    "# Scrape the website and return lists of books, authors and average review\n",
    "goodreads_list, author_list, review_list = get_listopia(this_week_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty book_data list to store the books in\n",
    "book_data = []\n",
    "\n",
    "# Iterate through the book list and check if it is on Gutenberg\n",
    "for count, book in enumerate(goodreads_list):\n",
    "    file_path, book_id = BookImporter.gutendex(book, author_list[count])\n",
    "    \n",
    "    # Store the book in the book list\n",
    "    book_data.append({'GutenbergID': book_id, 'Title': book, 'Author': author_list[count], 'Review': review_list[count], 'FilePath': file_path})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   GutenbergID  100 non-null    int64 \n",
      " 1   Title        100 non-null    object\n",
      " 2   Author       100 non-null    object\n",
      " 3   Review       100 non-null    object\n",
      " 4   FilePath     21 non-null     object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Convert the book list into a pandas and check for missing values\n",
    "book_data = pd.DataFrame(book_data)\n",
    "book_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Duplicates (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    GutenbergID                  Title      Author Review FilePath\n",
      "93            0  To Kill a Mockingbird  Harper Lee   4.27     None\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "duplicates = book_data.duplicated()\n",
    "\n",
    "duplicate_rows = book_data[duplicates]\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are any duplicate values (check by title and author), remove them\n",
    "book_data = book_data.drop_duplicates(subset=['Title', 'Author'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GutenbergID                                              Title   \n",
      "0            0            The Hunger Games (The Hunger Games, #1)  \\\n",
      "1            0  Harry Potter and the Order of the Phoenix (Har...   \n",
      "2         1342                                Pride and Prejudice   \n",
      "3            0                              To Kill a Mockingbird   \n",
      "4            0                                     The Book Thief   \n",
      "\n",
      "            Author Review                      FilePath  \n",
      "0  Suzanne Collins   4.33                          None  \n",
      "1     J.K. Rowling   4.50                          None  \n",
      "2      Jane Austen   4.28  data/Pride_and_Prejudice.txt  \n",
      "3       Harper Lee   4.27                          None  \n",
      "4     Markus Zusak   4.39                          None  \n"
     ]
    }
   ],
   "source": [
    "# Check the dataframe\n",
    "print(book_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Name\n",
      "0                Suzanne Collins\n",
      "1                   J.K. Rowling\n",
      "2                    Jane Austen\n",
      "3                     Harper Lee\n",
      "4                   Markus Zusak\n",
      "..                           ...\n",
      "84               Edgar Allan Poe\n",
      "85            Barbara Kingsolver\n",
      "86                     Anne Rice\n",
      "87  Miguel de Cervantes Saavedra\n",
      "88              Ernest Hemingway\n",
      "\n",
      "[89 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get a list of unique author names\n",
    "author_list = book_data['Author'].unique()\n",
    "author_list_df = pd.DataFrame({'Name': author_list})\n",
    "\n",
    "print(author_list_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data to SQL database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start up SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the SQL database \n",
    "conn = sqlite3.connect('databases/book_repository.db')\n",
    "cursor = conn.cursor()\n",
    "engine = create_engine('sqlite:///databases/book_repository.db')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the tables (Commented out after the first iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Authors table\n",
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS Authors(\n",
    "            AuthorID INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            Name VARCHAR\n",
    "        )\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gutenberg table\n",
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Gutenberg(\n",
    "        GutenbergID INTEGER PRIMARY KEY,\n",
    "        FilePath VARCHAR\n",
    "        );\n",
    "    ''')\n",
    "        # If there is not GutenbergID, it will reference this\n",
    "    conn.execute('''\n",
    "        INSERT OR IGNORE INTO Gutenberg (GutenbergID, FilePath)\n",
    "        VALUES (0, 'Not Available')\n",
    "        ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Books table\n",
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Books(\n",
    "        GutenbergID VARCHAR(7),\n",
    "        Title VARCHAR,\n",
    "        AuthorID INTEGER,\n",
    "        Review DOUBLE,\n",
    "        FOREIGN KEY (GutenbergID) REFERENCES Gutenberg(GutenbergID)\n",
    "        FOREIGN KEY (AuthorID) REFERENCES Authors(AuthorID)\n",
    "        );\n",
    "''')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the data in a temporary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the books data into a temporary SQL table\n",
    "book_data.to_sql('temp_books', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the author list into a temporary SQL table\n",
    "author_list_df.to_sql('temp_authors', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the author names into the table, ignore repetitions\n",
    "with engine.begin() as connection:\n",
    "    conn.execute(\"\"\"\n",
    "        INSERT INTO Authors (Name)\n",
    "        SELECT DISTINCT LOWER(t.Name)\n",
    "        FROM temp_authors AS t\n",
    "        LEFT JOIN Authors AS a ON LOWER(t.Name) = LOWER(a.Name)\n",
    "        WHERE a.Name IS NULL\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "        INSERT INTO Gutenberg (GutenbergID, FilePath)\n",
    "        SELECT t.GutenbergID, t.FilePath\n",
    "        FROM temp_books as t\n",
    "        LEFT JOIN Gutenberg AS g ON t.GutenbergID = g.GutenbergID\n",
    "        WHERE t.FilePath IS NOT NULL\n",
    "          AND (g.GutenbergID IS NULL OR g.GutenbergID = 0)\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the rest of the Book data, with the foreign keys\n",
    "with engine.begin() as connection:\n",
    "    conn.execute('''\n",
    "        INSERT INTO Books (GutenbergID, Title, AuthorID, Review)\n",
    "        SELECT t.GutenbergID, t.Title, a.AuthorID, t.Review\n",
    "        FROM temp_books AS t\n",
    "        LEFT JOIN Authors AS a ON LOWER(t.Author) = LOWER(a.Name)\n",
    "        LEFT JOIN Books AS b ON t.GutenbergID = b.GutenbergID\n",
    "        WHERE b.GutenbergID IS NULL\n",
    "    ''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the temporary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the temporary tables\n",
    "with engine.begin() as connection:\n",
    "    conn.execute(\"DROP TABLE IF EXISTS temp_books\")\n",
    "    conn.execute('DROP TABLE IF EXISTS temp_authors')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hunger Games (The Hunger Games, #1): suzanne collins, 0\n",
      "Harry Potter and the Order of the Phoenix (Harry Potter, #5): j.k. rowling, 0\n",
      "Pride and Prejudice: jane austen, 1342\n",
      "To Kill a Mockingbird: harper lee, 0\n",
      "The Book Thief: markus zusak, 0\n",
      "Twilight (The Twilight Saga, #1): stephenie meyer, 0\n",
      "Animal Farm: george orwell, 0\n",
      "J.R.R. Tolkien 4-Book Boxed Set: The Hobbit and The Lord of the Rings: j.r.r. tolkien, 0\n",
      "The Chronicles of Narnia (Chronicles of Narnia, #1-7): c.s. lewis, 0\n",
      "The Fault in Our Stars: john green, 0\n",
      "Gone with the Wind: margaret mitchell, 0\n",
      "The Giving Tree: shel silverstein, 0\n",
      "The Picture of Dorian Gray: oscar wilde, 174\n",
      "Wuthering Heights: emily brontë, 768\n",
      "Harry Potter and the Philosopher’s Stone (Harry Potter, #1): j.k. rowling, 0\n",
      "The Perks of Being a Wallflower: stephen chbosky, 0\n",
      "Jane Eyre: charlotte brontë, 1260\n",
      "The Da Vinci Code (Robert Langdon, #2): dan brown, 0\n",
      "The Great Gatsby: f. scott fitzgerald, 64317\n",
      "The Little Prince: antoine de saint-exupéry, 0\n",
      "Alice's Adventures in Wonderland / Through the Looking-Glass: lewis carroll, 0\n",
      "Memoirs of a Geisha: arthur golden, 0\n",
      "The Lightning Thief (Percy Jackson and the Olympians, #1): rick riordan, 0\n",
      "Divergent (Divergent, #1): veronica roth, 0\n",
      "Les Misérables: victor hugo, 135\n",
      "Crime and Punishment: fyodor dostoevsky, 0\n",
      "Lord of the Flies: william golding, 0\n",
      "Romeo and Juliet: william shakespeare, 1513\n",
      "Anne of Green Gables (Anne of Green Gables, #1): l.m. montgomery, 0\n",
      "City of Bones (The Mortal Instruments, #1): cassandra clare, 0\n",
      "The Hitchhiker's Guide to the Galaxy (The Hitchhiker's Guide to the Galaxy, #1): douglas adams, 39\n",
      "The Help: kathryn stockett, 0\n",
      "Ender’s Game (Ender's Saga, #1): orson scott card, 0\n",
      "Charlotte's Web: e.b. white, 0\n",
      "Dracula: bram stoker, 345\n",
      "Of Mice and Men: john steinbeck, 0\n",
      "The Alchemist: paulo coelho, 0\n",
      "The Catcher in the Rye: j.d. salinger, 0\n",
      "Brave New World: aldous huxley, 0\n",
      "One Hundred Years of Solitude: gabriel garcía márquez, 0\n",
      "Fahrenheit 451: ray bradbury, 0\n",
      "The Time Traveler's Wife: audrey niffenegger, 0\n",
      "A Thousand Splendid Suns: khaled hosseini, 0\n",
      "The Princess Bride: william goldman, 0\n",
      "The Secret Garden: frances hodgson burnett, 17396\n",
      "A Game of Thrones (A Song of Ice and Fire, #1): george r.r. martin, 0\n",
      "The Outsiders: s.e. hinton, 0\n",
      "A Wrinkle in Time (Time Quintet, #1): madeleine l'engle, 0\n",
      "The Odyssey: homer, 1727\n",
      "Little Women: louisa may alcott, 37106\n",
      "1984: george orwell, 0\n",
      "The Adventures of Huckleberry Finn: mark twain, 32325\n",
      "The Lovely Bones: alice sebold, 0\n",
      "The Kite Runner: khaled hosseini, 0\n",
      "Where the Wild Things Are: maurice sendak, 0\n",
      "Frankenstein: The 1818 Text: mary wollstonecraft shelley, 0\n",
      "Green Eggs and Ham: dr. seuss, 0\n",
      "Life of Pi: yann martel, 0\n",
      "A Tale of Two Cities: charles dickens, 98\n",
      "The Handmaid’s Tale (The Handmaid's Tale, #1): margaret atwood, 0\n",
      "Harry Potter and the Deathly Hallows (Harry Potter, #7): j.k. rowling, 0\n",
      "The Giver (The Giver, #1): lois lowry, 0\n",
      "Lolita: vladimir nabokov, 0\n",
      "Water for Elephants: sara gruen, 0\n",
      "Slaughterhouse-Five: kurt vonnegut jr., 0\n",
      "Dune (Dune, #1): frank herbert, 0\n",
      "Harry Potter and the Prisoner of Azkaban (Harry Potter, #3): j.k. rowling, 0\n",
      "The Stand: stephen king, 0\n",
      "Catch-22: joseph heller, 0\n",
      "The Bell Jar: sylvia plath, 0\n",
      "Matilda: roald dahl, 0\n",
      "The Pillars of the Earth (Kingsbridge, #1): ken follett, 0\n",
      "The Adventures of Sherlock Holmes (Sherlock Holmes, #3): arthur conan doyle, 1661\n",
      "Watership Down (Watership Down, #1): richard  adams, 0\n",
      "Great Expectations: charles dickens, 1400\n",
      "Rebecca: daphne du maurier, 0\n",
      "The Girl with the Dragon Tattoo (Millennium, #1): stieg larsson, 0\n",
      "Outlander (Outlander, #1): diana gabaldon, 0\n",
      "One Flew Over the Cuckoo's Nest: ken kesey, 0\n",
      "The Color Purple: alice walker, 0\n",
      "The Fellowship of the Ring (The Lord of the Rings, #1): j.r.r. tolkien, 0\n",
      "My Sister's Keeper: jodi picoult, 0\n",
      "Anna Karenina: leo tolstoy, 1399\n",
      "The Brothers Karamazov: fyodor dostoevsky, 0\n",
      "A Tree Grows in Brooklyn: betty  smith, 0\n",
      "A Clockwork Orange: anthony burgess, 0\n",
      "The Road: cormac mccarthy, 0\n",
      "Angela's Ashes (Frank McCourt, #1): frank mccourt, 0\n",
      "Siddhartha: hermann hesse, 2500\n",
      "Vampire Academy (Vampire Academy, #1): richelle mead, 0\n",
      "The Golden Compass (His Dark Materials, #1): philip pullman, 0\n",
      "And Then There Were None: agatha christie, 0\n",
      "It: stephen king, 7947\n",
      "The Complete Stories and Poems: edgar allan poe, 0\n",
      "The Shining (The Shining, #1): stephen king, 0\n",
      "The Poisonwood Bible: barbara kingsolver, 0\n",
      "Interview with the Vampire (The Vampire Chronicles, #1): anne rice, 0\n",
      "Don Quixote: miguel de cervantes saavedra, 996\n",
      "The Old Man and the Sea: ernest hemingway, 13923\n",
      "Tomorrow, and Tomorrow, and Tomorrow: gabrielle zevin, 6711\n",
      "The Lord of the Rings: j.r.r. tolkien, 70333\n",
      "The Count of Monte Cristo: alexandre dumas, 1184\n",
      "Sense and Sensibility: jane austen, 161\n",
      "The Scarlet Letter: nathaniel hawthorne, 25344\n",
      "War and Peace: leo tolstoy, 2600\n",
      "Emma: jane austen, 158\n",
      "A Christmas Carol: charles dickens, 46\n",
      "Treasure Island: robert louis stevenson, 120\n",
      "Persuasion: jane austen, 105\n",
      "Dr. Jekyll and Mr. Hyde: robert louis stevenson, 43\n",
      "The Hound of the Baskervilles (Sherlock Holmes, #5): arthur conan doyle, 2852\n",
      "Moby-Dick or, the Whale: herman melville, 15\n",
      "Madame Bovary: gustave flaubert, 2413\n",
      "The Name of the Rose: umberto eco, 60819\n",
      "Oliver Twist: charles dickens, 730\n",
      "Robinson Crusoe: daniel defoe, 521\n",
      "Uncle Tom's Cabin: harriet beecher stowe, 203\n",
      "The Trial: franz kafka, 7849\n",
      "Love in the Time of Cholera: gabriel garcía márquez, 26050\n",
      "The Sun Also Rises: ernest hemingway, 67138\n",
      "Candide: voltaire, 19942\n",
      "The Call of the Wild: jack london, 215\n",
      "The Arabian Nights: anonymous, 47285\n",
      "Mansfield Park: jane austen, 141\n",
      "Tess of the D'Urbervilles: thomas hardy, 110\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "# Check to see if the Data was inserted correctly\n",
    "cursor.execute('''\n",
    "    SELECT Books.Title, Authors.Name, Books.GutenbergID\n",
    "    FROM Books\n",
    "    LEFT OUTER JOIN Authors ON Books.AuthorID = Authors.AuthorID\n",
    "''')\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(f'{row[0]}: {row[1]}, {row[2]}')\n",
    "print(len(rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0: Not Available\n",
      "     15: data/Moby-Dick_or,_the_Whale.txt\n",
      "     39: data/The_Hitchhiker's_Guide_to_the_Galaxy_(The_Hitchhiker's_Guide_to_the_Galaxy,_#1).txt\n",
      "     43: data/Dr._Jekyll_and_Mr._Hyde.txt\n",
      "     46: data/A_Christmas_Carol.txt\n",
      "     98: data/A_Tale_of_Two_Cities.txt\n",
      "    105: data/Persuasion.txt\n",
      "    110: data/Tess_of_the_D'Urbervilles.txt\n",
      "    120: data/Treasure_Island.txt\n",
      "    135: data/Les_Misérables.txt\n",
      "    141: data/Mansfield_Park.txt\n",
      "    158: data/Emma.txt\n",
      "    161: data/Sense_and_Sensibility.txt\n",
      "    174: data/The_Picture_of_Dorian_Gray.txt\n",
      "    203: data/Uncle_Tom's_Cabin.txt\n",
      "    215: data/The_Call_of_the_Wild.txt\n",
      "    345: data/Dracula.txt\n",
      "    521: data/Robinson_Crusoe.txt\n",
      "    730: data/Oliver_Twist.txt\n",
      "    768: data/Wuthering_Heights.txt\n",
      "    996: data/Don_Quixote.txt\n",
      "   1184: data/The_Count_of_Monte_Cristo.txt\n",
      "   1260: data/Jane_Eyre.txt\n",
      "   1342: data/Pride_and_Prejudice.txt\n",
      "   1399: data/Anna_Karenina.txt\n",
      "   1400: data/Great_Expectations.txt\n",
      "   1513: data/Romeo_and_Juliet.txt\n",
      "   1661: data/The_Adventures_of_Sherlock_Holmes_(Sherlock_Holmes,_#3).txt\n",
      "   1727: data/The_Odyssey.txt\n",
      "   2413: data/Madame_Bovary.txt\n",
      "   2500: data/Siddhartha.txt\n",
      "   2600: data/War_and_Peace.txt\n",
      "   2852: data/The_Hound_of_the_Baskervilles_(Sherlock_Holmes,_#5).txt\n",
      "   6711: data/Tomorrow,_and_Tomorrow,_and_Tomorrow.txt\n",
      "   7849: data/The_Trial.txt\n",
      "   7947: data/It.txt\n",
      "  13923: data/The_Old_Man_and_the_Sea.txt\n",
      "  17396: data/The_Secret_Garden.txt\n",
      "  19942: data/Candide.txt\n",
      "  25344: data/The_Scarlet_Letter.txt\n",
      "  26050: data/Love_in_the_Time_of_Cholera.txt\n",
      "  32325: data/The_Adventures_of_Huckleberry_Finn.txt\n",
      "  37106: data/Little_Women.txt\n",
      "  47285: data/The_Arabian_Nights.txt\n",
      "  60819: data/The_Name_of_the_Rose.txt\n",
      "  64317: data/The_Great_Gatsby.txt\n",
      "  67138: data/The_Sun_Also_Rises.txt\n",
      "  70333: data/The_Lord_of_the_Rings.txt\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# Check if the Gutenberg table was inserted correctly\n",
    "cursor.execute('SELECT * FROM Gutenberg')\n",
    "\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(f'{row[0]:>7}: {row[1]}')\n",
    "print(len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Not Available')]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute('SELECT * FROM Gutenberg WHERE GutenbergID=0')\n",
    "print(cursor.fetchall())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit any unsaved changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SQL server\n",
    "conn.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NLP and add TextBlob to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the large dataset and add the TextBlob pipeline\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe('spacytextblob')\n",
    "\n",
    "# Create a books list to store the Book objects\n",
    "books = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the files and analyse the novels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jekyll and Hyde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Jekyll and Hyde from Gutenberg\n",
    "BookImporter.get_book(43, 'Jekyll and Hyde')\n",
    "\n",
    "# Read the txt file and create a Book object\n",
    "with open('data\\Jekyll_and_Hyde.txt', 'r', encoding='UTF-8') as file:\n",
    "    jekyll_hyde = Book('Jekyll and Hyde', file.read())\n",
    "\n",
    "# Denote the chapter markers in a regex expression\n",
    "chapter_markers = r'((\\nSTORY OF THE DOOR)|(\\nSEARCH FOR MR. HYDE)|(\\nDR. JEKYLL WAS QUITE AT EASE)|(\\nTHE CAREW MURDER CASE)|(\\nINCIDENT OF THE LETTER)|(\\nINCIDENT OF DR. LANYON)|(\\nINCIDENT AT THE WINDOW)|(\\nTHE LAST NIGHT)|(\\nDR. LANYON’S NARRATIVE)|(\\nHENRY JEKYLL’S FULL STATEMENT OF THE CASE))'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the book into chapters\n",
    "jekyll_hyde.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct NLP analysis sentence by sentence\n",
    "jekyll_hyde.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do NLP on each chapter\n",
    "jekyll_hyde.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sentiment analysis of the entire text\n",
    "jekyll_hyde.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the analysis of the book\n",
    "jekyll_hyde.get_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the sentiment analysis by chapter\n",
    "jekyll_hyde.chapter_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the book to the book object list\n",
    "books.append(jekyll_hyde)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dracula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\Dracula.txt', 'r', encoding='UTF-8') as file:\n",
    "    dracula = Book('Dracula', file.read())\n",
    "chapter_markers = r'(PREFACE.)|(LETTER I+\\.)|(CHAPTER [IVXLCDM]+\\n)'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dracula.chapter_analysis()\n",
    "books.append(dracula)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frankenstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(84, 'Frankenstein')\n",
    "with open('data\\Frankenstein.txt', 'r', encoding='UTF-8') as file:\n",
    "    frankenstein = Book('Frankenstein', file.read())\n",
    "\n",
    "chapter_markers = r'\\n((Letter .)|(Chapter .+))'\n",
    "frankenstein.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frankenstein.chapter_analysis()\n",
    "books.append(frankenstein)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Turn of the Screw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(209, 'The Turn of the Screw')\n",
    "with open('data\\The_Turn_of_the_Screw.txt', 'r', encoding='UTF-8') as file:\n",
    "    turn_of_the_screw = Book('The Turn of the Screw', file.read())\n",
    "\n",
    "chapter_markers = r'((\\nI\\n)|(\\nII)|(\\nIII)|(\\nIV)|(\\nV)|(\\nVI)|(\\nVII)|(\\nVIII)|(\\nIX)|(\\nX)|(\\nXI)|(\\nXII)|(\\nXIII)|(\\nXIV)|(\\nXV)|(\\nXVI)|(\\nXVII)|(\\nXVIII)|(\\nXIX)|(\\nXX)|(\\nXXI)|(\\nXXII)|(\\nXXIII)|(\\nXXIV))'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_of_the_screw.chapter_analysis()\n",
    "books.append(turn_of_the_screw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Romeo and Juliet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(1513, 'Romeo and Juliet')\n",
    "with open('data\\Romeo_and_Juliet.txt', 'r', encoding='UTF-8') as file:\n",
    "    romeo_and_juliet = Book('Romeo and Juliet', file.read())\n",
    "\n",
    "chapter_markers = r'(THE PROLOGUE\\n)|(SCENE I. A public place)|(SCENE II. A Street)|(SCENE III. Room in Capulet’s House)|(SCENE IV. A Street)|(SCENE V. A Hall in Capulet’s House)|(ACT II\\n\\n)|(SCENE I. An open place adjoining Capulet’s Garden)|(SCENE II. Capulet’s Garden)|(SCENE III. Friar Lawrence’s Cell)|(SCENE IV. A Street)|(SCENE V. Capulet’s Garden)|(SCENE VI. Friar Lawrence’s Cell)|(SCENE I. A public Place)|(SCENE II. A Room in Capulet’s House)|(SCENE III. Friar Lawrence’s cell)|(SCENE IV. A Room in Capulet’s House)|(SCENE V. An open Gallery to Juliet’s Chamber, overlooking the Garden)|(SCENE I. Friar Lawrence’s Cell)|(SCENE II. Hall in Capulet’s House)|(SCENE III. Juliet’s Chamber)|(SCENE IV. Hall in Capulet’s House)|(SCENE V. Juliet’s Chamber; Juliet on the bed)|(SCENE I. Mantua. A Street)|(SCENE II. Friar Lawrence’s Cell)|(SCENE III. A churchyard; in it a Monument belonging to the Capulets)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romeo_and_juliet.chapter_analysis()\n",
    "books.append(romeo_and_juliet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alice's Adventures in Wonderland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(11, 'Alice’s Adventures in Wonderland')\n",
    "with open('data\\Alice’s_Adventures_in_Wonderland.txt', 'r', encoding='UTF-8') as file:\n",
    "    alice = Book('Alice in Wonderland', file.read())\n",
    "chapter_markers = r'(CHAPTER I.\\nDown the Rabbit-Hole)|(CHAPTER II.\\nThe Pool of Tears)|(CHAPTER III.\\nA Caucus-Race and a Long Tale)|(CHAPTER IV.\\nThe Rabbit Sends in a Little Bill)|(CHAPTER V.\\nAdvice from a Caterpillar)|(CHAPTER VI.\\nPig and Pepper)|(CHAPTER VII.\\nA Mad Tea-Party)|(CHAPTER VIII.\\nThe Queen’s Croquet-Ground)|(CHAPTER IX.\\nThe Mock Turtle’s Story)|(CHAPTER X.\\nThe Lobster Quadrille)|(CHAPTER XI.\\nWho Stole the Tarts\\?)|(CHAPTER XII.\\nAlice’s Evidence)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice.chapter_analysis()\n",
    "books.append(alice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The War of the Worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(36, 'War of the Worlds')\n",
    "with open('data\\War_of_the_Worlds.txt', 'r', encoding='UTF-8') as file:\n",
    "    war_of_the_worlds = Book('War of the Worlds', file.read())\n",
    "\n",
    "chapter_markers = r'\\n[IVX]+\\.\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_of_the_worlds.chapter_analysis()\n",
    "books.append(war_of_the_worlds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wuthering Heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\Wuthering_Heights.txt', 'r', encoding='UTF-8') as file:\n",
    "    wuthering_heights = Book('Wuthering Heights', file.read())\n",
    "\n",
    "chapter_markers = r'CHAPTER [IVX]+'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.do_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuthering_heights.chapter_analysis()\n",
    "books.append(wuthering_heights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pride and Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\Pride_and_Prejudice.txt', 'r', encoding='UTF-8') as file:\n",
    "    pride_prejudice = Book('Pride and Prejudice', file.read())\n",
    "\n",
    "chapter_markers = r'(Chapter I\\.\\])|CHAPTER [IVXL]+\\.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.split_into_chapters(chapter_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.do_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.chapter_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pride_prejudice.chapter_analysis()\n",
    "books.append(pride_prejudice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\Moby-Dick_or,_the_Whale.txt', 'r', encoding='UTF-8') as file:\n",
    "    moby_dick = Book('Moby Dick', file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r'(\\nCHAPTER .+)|(\\nEPILOGUE.)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "moby_dick.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.do_nlp(nlp, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick.chapter_analysis()\n",
    "books.append(moby_dick)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ulysses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BookImporter.get_book(4300, 'Ulysses')\n",
    "with open('data\\\\Ulysses.txt', 'r', encoding='UTF-8') as file:\n",
    "    ulysses = Book('Ulysses', file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r''\n",
    "for i in range(1, 18):\n",
    "    chapter_markers += r'(\\n\\[ {} \\])|'.format(i)\n",
    "chapter_markers += r'(\\n\\[ 18 \\])'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ulysses.split_into_chapters(chapter_markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulysses.do_nlp(nlp, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulysses.chapter_nlp(nlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulysses.blobify()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ulysses.get_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulysses.chapter_analysis()\n",
    "books.append(ulysses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Christmas Carol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\A_Christmas_Carol.txt', 'r', encoding='UTF-8') as file:\n",
    "    christmas_carol = Book('A Christmas Carol', file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r'STAVE (.+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.split_into_chapters(chapter_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.do_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.chapter_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.get_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "christmas_carol.chapter_analysis()\n",
    "books.append(christmas_carol)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dorian Grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\The_Picture_of_Dorian_Gray.txt', 'r', encoding='UTF-8') as file:\n",
    "    dorian_gray = Book('The Picture of Dorian Gray', file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r'\\n(CHAPTER .+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.split_into_chapters(chapter_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.do_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.chapter_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.get_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorian_gray.chapter_analysis()\n",
    "books.append(dorian_gray)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## War and Peace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data\\War_and_Peace.txt', 'r', encoding='UTF-8') as file:\n",
    "    war_and_peace = Book('War and Peace', file.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_markers = r'\\nCHAPTER [IXVC]+\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.split_into_chapters(chapter_markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.do_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.chapter_nlp(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.blobify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.get_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "war_and_peace.chapter_analysis()\n",
    "books.append(war_and_peace)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct similarity analysis and display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a similarity analysis between each book in the books list\n",
    "checker = SimilarityChecker(books)\n",
    "checker.calculate_all_similarities()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results of the similarity analysis\n",
    "checker.display_matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
